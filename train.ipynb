{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.layers import Dense, Dropout, Activation, BatchNormalization, Input\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "morgan_train = pd.read_csv('data/morgan_0_train.csv')\n",
    "morgan_test = pd.read_csv('data/morgan_0_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_train = pd.read_csv('data/pcad_cells_0_train.csv')\n",
    "cell_test = pd.read_csv('data/pcad_cells_0_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat((morgan_train, cell_train), axis=1)\n",
    "X_test = pd.concat((morgan_test, cell_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.read_csv('data/y_train_0.csv')\n",
    "y_test = pd.read_csv('data/y_test_0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.to_numpy()\n",
    "X_test = X_test.to_numpy()\n",
    "y_train = y_train.to_numpy()\n",
    "y_test = y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_dim):\n",
    "    input_layer = Input(shape=(input_dim,))\n",
    "    _ = Dense(units=1024)(input_layer)\n",
    "    _ = BatchNormalization()(_)\n",
    "    _ = Activation('relu')(_)\n",
    "    _ = Dense(units=512)(_)\n",
    "    _ = BatchNormalization()(_)\n",
    "    _ = Activation('relu')(_)\n",
    "    _ = Dropout(0.5)(_)\n",
    "    _ = Dense(units=256)(_)\n",
    "    _ = BatchNormalization()(_)\n",
    "    _ = Activation('relu')(_)\n",
    "    _ = Dropout(0.25)(_)\n",
    "    _ = Dense(units=128)(_)\n",
    "    _ = BatchNormalization()(_)\n",
    "    _ = Activation('relu')(_)\n",
    "    _ = Dropout(0.25)(_)\n",
    "    output_layer = Dense(units=1, activation='linear')(_)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    opt = Adam(learning_rate=0.01)\n",
    "    model.compile(optimizer=opt, loss='mse')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5215/5215 [==============================] - 41s 8ms/step - loss: 3.6763 - val_loss: 1.7693\n",
      "Epoch 2/100\n",
      "5215/5215 [==============================] - 41s 8ms/step - loss: 2.1172 - val_loss: 1.4885\n",
      "Epoch 3/100\n",
      "4517/5215 [========================>.....] - ETA: 5s - loss: 1.9188"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-b0dcada105ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr2_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    535\u001b[0m       \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mnumber\u001b[0m \u001b[0mof\u001b[0m \u001b[0marguments\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mincorrect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m     \"\"\"\n\u001b[0;32m--> 537\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    538\u001b[0m       raise ValueError(\n\u001b[1;32m    539\u001b[0m           \u001b[0;34m\"Arguments and signature arguments do not match. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = build_model(X_train.shape[1])\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=16, epochs=100, verbose=1)\n",
    "\n",
    "y_preds = model.predict(X_test)\n",
    "print(r2_score(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24921311596014617\n",
      "2.3806705963604116\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.linear_model import Ridge\n",
    "regressor = Ridge(alpha=50, max_iter=10000)\n",
    "regressor.fit(X_train, y_train)\n",
    "y_preds = regressor.predict(X_test)\n",
    "print(r2_score(y_test, y_preds))\n",
    "print(sqrt(mean_squared_error(y_test, y_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5215/5215 [==============================] - 40s 8ms/step - loss: 6.9191 - val_loss: 6.2108\n",
      "Epoch 2/100\n",
      "5215/5215 [==============================] - 39s 8ms/step - loss: 5.0167 - val_loss: 3.6432\n",
      "Epoch 3/100\n",
      "5215/5215 [==============================] - 39s 7ms/step - loss: 4.0731 - val_loss: 7.3637\n",
      "Epoch 4/100\n",
      "5215/5215 [==============================] - 39s 8ms/step - loss: 3.4300 - val_loss: 5.8035\n",
      "Epoch 5/100\n",
      "5215/5215 [==============================] - 40s 8ms/step - loss: 3.0863 - val_loss: 3.1014\n",
      "Epoch 6/100\n",
      "5215/5215 [==============================] - 40s 8ms/step - loss: 2.9361 - val_loss: 2.7652\n",
      "Epoch 7/100\n",
      "5215/5215 [==============================] - 39s 8ms/step - loss: 2.8480 - val_loss: 2.4480\n",
      "Epoch 8/100\n",
      "5215/5215 [==============================] - 40s 8ms/step - loss: 2.7292 - val_loss: 2.4753\n",
      "Epoch 9/100\n",
      "5215/5215 [==============================] - 41s 8ms/step - loss: 2.6285 - val_loss: 2.4041\n",
      "Epoch 10/100\n",
      "5215/5215 [==============================] - 39s 7ms/step - loss: 2.5436 - val_loss: 2.0267\n",
      "Epoch 11/100\n",
      "5215/5215 [==============================] - 39s 7ms/step - loss: 2.4773 - val_loss: 3.9517\n",
      "Epoch 12/100\n",
      "5215/5215 [==============================] - 39s 8ms/step - loss: 2.3827 - val_loss: 2.5163\n",
      "Epoch 13/100\n",
      "5215/5215 [==============================] - 39s 8ms/step - loss: 2.3691 - val_loss: 2.5595\n",
      "Epoch 14/100\n",
      "5215/5215 [==============================] - 39s 7ms/step - loss: 2.3538 - val_loss: 1.8715\n",
      "Epoch 15/100\n",
      "5215/5215 [==============================] - 40s 8ms/step - loss: 2.3125 - val_loss: 1.9348\n",
      "Epoch 16/100\n",
      "5215/5215 [==============================] - 40s 8ms/step - loss: 2.2538 - val_loss: 2.0284\n",
      "Epoch 17/100\n",
      "5215/5215 [==============================] - 40s 8ms/step - loss: 2.2749 - val_loss: 1.6973\n",
      "Epoch 18/100\n",
      "5215/5215 [==============================] - 41s 8ms/step - loss: 2.2270 - val_loss: 2.4503\n",
      "Epoch 19/100\n",
      "5215/5215 [==============================] - 40s 8ms/step - loss: 2.1680 - val_loss: 1.6234\n",
      "Epoch 20/100\n",
      "5215/5215 [==============================] - 40s 8ms/step - loss: 2.1398 - val_loss: 2.3310\n",
      "Epoch 21/100\n",
      "5215/5215 [==============================] - 40s 8ms/step - loss: 2.1363 - val_loss: 1.6510\n",
      "Epoch 22/100\n",
      "5215/5215 [==============================] - 40s 8ms/step - loss: 2.0809 - val_loss: 1.7680\n",
      "Epoch 23/100\n",
      "5215/5215 [==============================] - 40s 8ms/step - loss: 1.8546 - val_loss: 1.8475\n",
      "Epoch 24/100\n",
      "5215/5215 [==============================] - 40s 8ms/step - loss: 1.7742 - val_loss: 1.4531\n",
      "Epoch 25/100\n",
      "5215/5215 [==============================] - 40s 8ms/step - loss: 1.7590 - val_loss: 1.7405\n",
      "Epoch 26/100\n",
      "5215/5215 [==============================] - 40s 8ms/step - loss: 1.7333 - val_loss: 1.8079\n",
      "Epoch 27/100\n",
      "5215/5215 [==============================] - 40s 8ms/step - loss: 1.7051 - val_loss: 2.1946\n",
      "Epoch 28/100\n",
      "5215/5215 [==============================] - 40s 8ms/step - loss: 1.7103 - val_loss: 1.4864\n",
      "Epoch 29/100\n",
      "5215/5215 [==============================] - 40s 8ms/step - loss: 1.6884 - val_loss: 2.8406\n",
      "Epoch 30/100\n",
      "5215/5215 [==============================] - 40s 8ms/step - loss: 1.6685 - val_loss: 1.7401\n",
      "Epoch 31/100\n",
      "5215/5215 [==============================] - 40s 8ms/step - loss: 1.6444 - val_loss: 1.5723\n",
      "Epoch 32/100\n",
      "5215/5215 [==============================] - 40s 8ms/step - loss: 1.6413 - val_loss: 1.7571\n",
      "Epoch 33/100\n",
      "5215/5215 [==============================] - 40s 8ms/step - loss: 1.6275 - val_loss: 1.7886\n",
      "Epoch 34/100\n",
      "5215/5215 [==============================] - 40s 8ms/step - loss: 1.6066 - val_loss: 1.9198\n",
      "Epoch 35/100\n",
      "5215/5215 [==============================] - 40s 8ms/step - loss: 1.5944 - val_loss: 1.4803\n",
      "Epoch 36/100\n",
      "5215/5215 [==============================] - 40s 8ms/step - loss: 1.5752 - val_loss: 1.9961\n",
      "Epoch 37/100\n",
      "5215/5215 [==============================] - 40s 8ms/step - loss: 1.5624 - val_loss: 1.6658\n",
      "Epoch 38/100\n",
      "5215/5215 [==============================] - 40s 8ms/step - loss: 1.5503 - val_loss: 1.4836\n",
      "Epoch 39/100\n",
      "5215/5215 [==============================] - 41s 8ms/step - loss: 1.5221 - val_loss: 1.6349\n",
      "Epoch 40/100\n",
      "5215/5215 [==============================] - 41s 8ms/step - loss: 1.5020 - val_loss: 1.6728\n",
      "Epoch 41/100\n",
      "5215/5215 [==============================] - 41s 8ms/step - loss: 1.4984 - val_loss: 1.8300\n",
      "Epoch 42/100\n",
      "5215/5215 [==============================] - 41s 8ms/step - loss: 1.4851 - val_loss: 1.3310\n",
      "Epoch 43/100\n",
      "5215/5215 [==============================] - 41s 8ms/step - loss: 1.4679 - val_loss: 2.0781\n",
      "Epoch 44/100\n",
      "5215/5215 [==============================] - 41s 8ms/step - loss: 1.4411 - val_loss: 1.2854\n",
      "Epoch 45/100\n",
      "5215/5215 [==============================] - 40s 8ms/step - loss: 1.4405 - val_loss: 1.5069\n",
      "Epoch 46/100\n",
      "5215/5215 [==============================] - 40s 8ms/step - loss: 1.4444 - val_loss: 1.4946\n",
      "Epoch 47/100\n",
      "5215/5215 [==============================] - 40s 8ms/step - loss: 1.4241 - val_loss: 1.3657\n",
      "Epoch 48/100\n",
      "5215/5215 [==============================] - 40s 8ms/step - loss: 1.4138 - val_loss: 1.6965\n",
      "Epoch 49/100\n",
      "5215/5215 [==============================] - 40s 8ms/step - loss: 1.3973 - val_loss: 1.5386\n",
      "Epoch 50/100\n",
      "5215/5215 [==============================] - 40s 8ms/step - loss: 1.3783 - val_loss: 1.4598\n",
      "Epoch 51/100\n",
      "5215/5215 [==============================] - 40s 8ms/step - loss: 1.3798 - val_loss: 1.5795\n",
      "Epoch 52/100\n",
      "5215/5215 [==============================] - 40s 8ms/step - loss: 1.3627 - val_loss: 1.2502\n",
      "Epoch 53/100\n",
      "5215/5215 [==============================] - 40s 8ms/step - loss: 1.3523 - val_loss: 1.1902\n",
      "Epoch 54/100\n",
      "5215/5215 [==============================] - 40s 8ms/step - loss: 1.3326 - val_loss: 1.5324\n",
      "Epoch 55/100\n",
      "5215/5215 [==============================] - 41s 8ms/step - loss: 1.3190 - val_loss: 1.4338\n",
      "Epoch 56/100\n",
      "5215/5215 [==============================] - 41s 8ms/step - loss: 1.3185 - val_loss: 4.9434\n",
      "Epoch 57/100\n",
      "5215/5215 [==============================] - 41s 8ms/step - loss: 1.3036 - val_loss: 1.5367\n",
      "Epoch 58/100\n",
      "5215/5215 [==============================] - 41s 8ms/step - loss: 1.3001 - val_loss: 1.9615\n",
      "Epoch 59/100\n",
      "5215/5215 [==============================] - 42s 8ms/step - loss: 1.2841 - val_loss: 1.2621\n",
      "Epoch 60/100\n",
      "5215/5215 [==============================] - 41s 8ms/step - loss: 1.2677 - val_loss: 1.2406\n",
      "Epoch 61/100\n",
      "5215/5215 [==============================] - 41s 8ms/step - loss: 1.2610 - val_loss: 1.4050\n",
      "Epoch 62/100\n",
      "5215/5215 [==============================] - 43s 8ms/step - loss: 1.2555 - val_loss: 1.3132\n",
      "Epoch 63/100\n",
      "5215/5215 [==============================] - 50s 10ms/step - loss: 1.2370 - val_loss: 1.5142\n",
      "Epoch 64/100\n",
      "5215/5215 [==============================] - 49s 9ms/step - loss: 1.2250 - val_loss: 1.2711\n",
      "Epoch 65/100\n",
      "5215/5215 [==============================] - 50s 10ms/step - loss: 1.2167 - val_loss: 1.2781\n",
      "Epoch 66/100\n",
      "5215/5215 [==============================] - 50s 10ms/step - loss: 1.2181 - val_loss: 3.4202\n",
      "Epoch 67/100\n",
      "5215/5215 [==============================] - 49s 9ms/step - loss: 1.2023 - val_loss: 1.1352\n",
      "Epoch 68/100\n",
      "5215/5215 [==============================] - 49s 9ms/step - loss: 1.1902 - val_loss: 1.2112\n",
      "Epoch 69/100\n",
      "5215/5215 [==============================] - 49s 9ms/step - loss: 1.1786 - val_loss: 1.4217\n",
      "Epoch 70/100\n",
      "5215/5215 [==============================] - 49s 9ms/step - loss: 1.1725 - val_loss: 1.1746\n",
      "Epoch 71/100\n",
      "5215/5215 [==============================] - 50s 10ms/step - loss: 1.1702 - val_loss: 1.2751\n",
      "Epoch 72/100\n",
      "5215/5215 [==============================] - 51s 10ms/step - loss: 1.1452 - val_loss: 2.2982\n",
      "Epoch 73/100\n",
      "5215/5215 [==============================] - 51s 10ms/step - loss: 1.1514 - val_loss: 1.2520\n",
      "Epoch 74/100\n",
      "5215/5215 [==============================] - 50s 10ms/step - loss: 1.1486 - val_loss: 1.1551\n",
      "Epoch 75/100\n",
      "5215/5215 [==============================] - 50s 10ms/step - loss: 1.1345 - val_loss: 1.1284\n",
      "Epoch 76/100\n",
      "5215/5215 [==============================] - 49s 9ms/step - loss: 1.1262 - val_loss: 1.5958\n",
      "Epoch 77/100\n",
      "5215/5215 [==============================] - 49s 9ms/step - loss: 1.1072 - val_loss: 1.1177\n",
      "Epoch 78/100\n",
      "5215/5215 [==============================] - 51s 10ms/step - loss: 1.1008 - val_loss: 1.1755\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5215/5215 [==============================] - 51s 10ms/step - loss: 1.0814 - val_loss: 1.2421\n",
      "Epoch 80/100\n",
      "5215/5215 [==============================] - 50s 10ms/step - loss: 1.0913 - val_loss: 1.3701\n",
      "Epoch 81/100\n",
      "5215/5215 [==============================] - 51s 10ms/step - loss: 1.0862 - val_loss: 1.1470\n",
      "Epoch 82/100\n",
      "5215/5215 [==============================] - 52s 10ms/step - loss: 1.0794 - val_loss: 1.0869\n",
      "Epoch 83/100\n",
      "5215/5215 [==============================] - 51s 10ms/step - loss: 1.0780 - val_loss: 1.0830\n",
      "Epoch 84/100\n",
      "5215/5215 [==============================] - 49s 9ms/step - loss: 1.0637 - val_loss: 1.4704\n",
      "Epoch 85/100\n",
      "5215/5215 [==============================] - 50s 10ms/step - loss: 1.0583 - val_loss: 1.1607\n",
      "Epoch 86/100\n",
      "5215/5215 [==============================] - 53s 10ms/step - loss: 1.0521 - val_loss: 1.1490\n",
      "Epoch 87/100\n",
      "5215/5215 [==============================] - 50s 10ms/step - loss: 1.0453 - val_loss: 1.3178\n",
      "Epoch 88/100\n",
      "5215/5215 [==============================] - 51s 10ms/step - loss: 1.0317 - val_loss: 1.0623\n",
      "Epoch 89/100\n",
      "5215/5215 [==============================] - 51s 10ms/step - loss: 1.0317 - val_loss: 1.8608\n",
      "Epoch 90/100\n",
      "5215/5215 [==============================] - 51s 10ms/step - loss: 1.0131 - val_loss: 3.0987\n",
      "Epoch 91/100\n",
      "5215/5215 [==============================] - 57s 11ms/step - loss: 1.0073 - val_loss: 1.3057\n",
      "Epoch 92/100\n",
      "5215/5215 [==============================] - 53s 10ms/step - loss: 1.0061 - val_loss: 1.0773\n",
      "Epoch 93/100\n",
      "5215/5215 [==============================] - 51s 10ms/step - loss: 0.9956 - val_loss: 1.2035\n",
      "Epoch 94/100\n",
      "5215/5215 [==============================] - 39s 7ms/step - loss: 0.9794 - val_loss: 1.4225\n",
      "Epoch 95/100\n",
      "5215/5215 [==============================] - 32s 6ms/step - loss: 0.9893 - val_loss: 1.2914\n",
      "Epoch 96/100\n",
      "5215/5215 [==============================] - 32s 6ms/step - loss: 0.9782 - val_loss: 1.0656\n",
      "Epoch 97/100\n",
      "5215/5215 [==============================] - 33s 6ms/step - loss: 0.9904 - val_loss: 1.1613\n",
      "Epoch 98/100\n",
      "5215/5215 [==============================] - 33s 6ms/step - loss: 0.9625 - val_loss: 1.6486\n",
      "Epoch 99/100\n",
      "5215/5215 [==============================] - 33s 6ms/step - loss: 0.9570 - val_loss: 1.3594\n",
      "Epoch 100/100\n",
      "5215/5215 [==============================] - 33s 6ms/step - loss: 0.9593 - val_loss: 1.1433\n",
      "0.8485461613953288\n"
     ]
    }
   ],
   "source": [
    "model = build_model(X_train.shape[1])\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), batch_size=16, epochs=100, verbose=1)\n",
    "\n",
    "y_preds = model.predict(X_test)\n",
    "print(r2_score(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.069254562333431"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sqrt(mean_squared_error(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: Fully_connectted_no_drop\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('Fully_connectted_no_drop')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
